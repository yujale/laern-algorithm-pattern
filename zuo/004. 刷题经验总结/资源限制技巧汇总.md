# 资源限制技巧汇总


#资源限制类题目

---

1）布隆过滤器用于集合的建立与查询，并可以节省大量空间  
2）一致性哈希解决数据服务器的负载管理问题  
3）利用并查集结构做岛问题的并行计算    
4）哈希函数可以把数据按照种类均匀分流  
5）位图解决某一范围上数字的出现情况，并可以节省大量空间  
6）利用分段统计思想、并进一步节省大量空间  
7）利用堆、[[外排序]]来做多个处理单元的结果合并  

---

Ref:
http://chenxii.cn/2019/06/08/D-DataStructureAndAlgorithm/G-BigDataProcess/bigData/

- 限制空间并且允许一定失误的映射查询
- 限制空间在海量数据中统计出现次数最多的
- 限制空间查找所有未出现的
- 限制空间查找一个未出现的
- 限制空间查找出现指定次数的
- 限制空间海量数据查找中位数
- 限制空间的海量数据TopK问题
- 哈希映射改变问题

---
http://chenxii.cn/2019/06/08/D-DataStructureAndAlgorithm/G-BigDataProcess/bigDataProcess/

- 海量日志数据，提取出某日访问百度次数最多的那个IP
- 寻找热门查询，300万个查询字符串中统计最热门的10个查询
- 有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词
- 海量数据分布在100台电脑中，高效统计出这批数据的TOP10
- 有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复，要求按照query的频度排序
- 怎么在海量数据中找出重复次数最多的一个？
- 上千万或上亿数据（有重复），统计其中出现次数最多的前N个数据
- 一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，请给出思想，给出时间复杂度分析。
- 1000万字符串，其中有些是重复的，需要把重复的全部去掉，保留没有重复的字符串。请怎么设计和实现？
- 一个文本文件，找出前10个经常出现的词，但这次文件比较长，说是上亿行或十亿行，总之无法一次读入内存，问最优解
- 100w个数中找出最大的100个数
- 2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数
- 5亿个int找中位数
- A,B两个文件，各存放50亿条URL，每条URL占用64字节，内存限制是4G，找出A,B文件共同的URL，如果是三个乃至n个文件呢？
- 有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16个字节，内存限制大小是1M。返回频数最高的100个词。





